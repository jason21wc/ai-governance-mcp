{
  "domain": "multi-agent",
  "principles": [
    {
      "id": "multi-A1",
      "domain": "multi-agent",
      "series_code": "A",
      "number": 1,
      "title": "Cognitive Function Specialization",
      "content": "### A1. Cognitive Function Specialization\n\n**Why This Principle Matters**\n\nIn the constitutional framework, MA1 (Role Segregation) establishes that distinct functions require specialized roles. For multi-agent systems, this translates to a fundamental architectural decision: agent boundaries should align with cognitive functions, not workflow phases. An agent optimized for strategic thinking operates differently than one optimized for critical analysis or creative generation. Mixing cognitive functions in one agent creates internal conflicts and reduces output quality.\n\n**Domain Application (Binding Rule)**\n\nEach agent must be assigned a single cognitive function with clear domain boundaries. Cognitive functions are mental models or reasoning patterns (strategic analysis, creative synthesis, critical evaluation, research compilation, etc.), not workflow steps. An agent may participate in multiple workflow phases if they require the same cognitive function.\n\n**Constitutional Basis**\n\n- MA1 (Role Segregation): Specialized roles for distinct functions\n- C2 (Single Source of Truth): Each cognitive function has one authoritative agent\n- O3 (DRY - Don't Repeat Yourself): Avoid cognitive function duplication across agents\n\n**Truth Sources**\n\n- Agent system prompt defining cognitive function and boundaries\n- Orchestrator documentation of agent-to-function mapping\n- Research demonstrating 70% cognitive load reduction with specialization\n\n**How AI Applies This Principle**\n\n1. Before creating agents, identify distinct cognitive functions required for the task\n2. Map each cognitive function to exactly one agent\n3. Write agent system prompts that define the single cognitive function clearly\n4. Prohibit agents from making decisions outside their cognitive domain\n5. Flag cross-domain decisions for orchestrator routing or human escalation\n\n**Success Criteria**\n\n- Each agent has exactly one defined cognitive function\n- Agent outputs contain no decisions outside their cognitive domain\n- Cross-domain requirements route through orchestrator\n- Agent system prompts explicitly state what is IN and OUT of scope\n\n**Human Interaction Points**\n\n- Define cognitive function boundaries for novel task types\n- Resolve ambiguous cognitive domain assignments\n- Approve agent specialization strategy for new multi-agent systems\n\n**Common Pitfalls**\n\n- **Function Bloat:** Assigning multiple cognitive functions to one agent \"for efficiency\"\n- **Phase Confusion:** Defining agents by workflow phase instead of cognitive function\n- **Boundary Creep:** Allowing agents to expand scope without explicit authorization\n\n**Configurable Defaults**\n\n- Maximum cognitive functions per agent: 1 (not configurable\u2014this is the principle)\n- Agent count: Determined by distinct cognitive functions required (no fixed limit)\n\n---\n",
      "line_range": [
        137,
        192
      ],
      "metadata": {
        "keywords": [
          "design",
          "architecture",
          "function",
          "structure",
          "specialization",
          "pattern",
          "cognitive"
        ],
        "synonyms": [
          "design",
          "structure",
          "layout",
          "framework"
        ],
        "trigger_phrases": [
          "agent architecture",
          "system design"
        ],
        "failure_indicators": [
          "poor design",
          "bad architecture",
          "structural issue"
        ],
        "aliases": [
          "A1"
        ]
      }
    },
    {
      "id": "multi-A2",
      "domain": "multi-agent",
      "series_code": "A",
      "number": 2,
      "title": "Context Isolation Architecture",
      "content": "### A2. Context Isolation Architecture\n\n**Why This Principle Matters**\n\nContext pollution\u2014where information from one domain inappropriately influences another\u2014is the primary cause of structural inconsistencies in multi-agent outputs. When agents share context windows or leak information between domains, errors compound rather than isolate. The constitutional principle C1 (Context Engineering) requires loading necessary information; for multi-agent systems, this means loading ONLY relevant information to EACH agent, preventing cross-contamination.\n\n**Domain Application (Binding Rule)**\n\nEach specialized agent must operate in a completely independent context window with zero unintended information cross-contamination between agents. Context flows through the orchestrator, not directly between execution agents. Each agent receives only context relevant to its cognitive function.\n\n**Constitutional Basis**\n\n- C1 (Context Engineering): Load necessary information\u2014implies NOT loading unnecessary information\n- MA2 (Handoffs): Transitions maintain state\u2014implies state is transferred explicitly, not leaked\n- O4 (Context Optimization): Minimize context consumption\u2014implies isolation prevents bloat\n\n**Truth Sources**\n\n- LangChain research: Subagent isolation saves 67% tokens vs. context accumulation\n- Anthropic research: Token usage explains 80% of performance variance\n- Factory.ai: \"Treat context as scarce, high-value resource\"\n\n**How AI Applies This Principle**\n\n1. Create fresh context windows for each specialized agent spawn\n2. Load only task-relevant information into each agent's context\n3. Route all inter-agent communication through orchestrator\n4. Never allow direct agent-to-agent context sharing\n5. Explicitly transfer required outputs, not full context histories\n\n**Success Criteria**\n\n- Each agent spawn begins with fresh context window\n- No agent can access another agent's internal reasoning or intermediate work\n- Orchestrator manages all context flow between agents\n- Context window utilization per agent is trackable and optimized\n\n**Human Interaction Points**\n\n- Approve context loading strategy for complex multi-agent workflows\n- Review context isolation when debugging unexpected agent behavior\n- Define what context is \"relevant\" for ambiguous tasks\n\n**Common Pitfalls**\n\n- **Context Dumping:** Passing full conversation history to sub-agents\n- **Shared Memory Anti-Pattern:** Using shared memory stores without access controls\n- **Result Bloat:** Passing verbose intermediate results instead of synthesized summaries\n\n**Configurable Defaults**\n\n- Maximum context transfer per handoff: Summary + essential inputs only (configurable per task complexity)\n- Context window monitoring: Required (tool-specific implementation)\n\n---\n",
      "line_range": [
        193,
        248
      ],
      "metadata": {
        "keywords": [
          "design",
          "architecture",
          "isolation",
          "structure",
          "pattern",
          "context"
        ],
        "synonyms": [
          "design",
          "structure",
          "layout",
          "framework"
        ],
        "trigger_phrases": [
          "agent architecture",
          "system design"
        ],
        "failure_indicators": [
          "poor design",
          "bad architecture",
          "structural issue"
        ],
        "aliases": [
          "A2"
        ]
      }
    },
    {
      "id": "multi-A3",
      "domain": "multi-agent",
      "series_code": "A",
      "number": 3,
      "title": "Orchestrator Separation Pattern",
      "content": "### A3. Orchestrator Separation Pattern\n\n**Why This Principle Matters**\n\nThe constitutional principle MA5 (Coordination Protocols) requires established protocols for agent interaction. In practice, this means a dedicated orchestrator must manage workflow, validation, and human interface WITHOUT executing domain-specific work. When an orchestrator also performs execution tasks, it becomes a \"do everything\" monolith that violates specialization and creates single points of failure. Separation of coordination from execution enables clear responsibility boundaries.\n\n**Domain Application (Binding Rule)**\n\nA dedicated orchestrator agent manages workflow coordination, validation gates, state tracking, and human interface. The orchestrator never executes phase-specific or domain-specific work\u2014it delegates to specialized agents. The orchestrator is the single point of interface for the human Product Owner.\n\n**Constitutional Basis**\n\n- MA5 (Coordination Protocols): Established protocols govern interaction\n- MA1 (Role Segregation): Orchestration is a distinct function from execution\n- G3 (Documentation): Orchestrator maintains authoritative workflow state\n\n**Truth Sources**\n\n- Microsoft Azure: Agent orchestration patterns with explicit coordinator roles\n- Google ADK: Hierarchical patterns with coordinator managing sub-agents\n- Enterprise patterns: Orchestrator agent coordinates without executing\n\n**How AI Applies This Principle**\n\n1. Define orchestrator with explicit coordination-only responsibilities\n2. Prohibit orchestrator from generating domain-specific outputs\n3. Route all human interactions through orchestrator\n4. Maintain workflow state, phase completion, and validation status in orchestrator\n5. Spawn specialized agents for all execution work\n\n**Success Criteria**\n\n- Orchestrator outputs contain only: workflow coordination, validation management, human interface, state tracking\n- No domain-specific implementations originate from orchestrator\n- All specialized work traces to a specialized agent\n- Human sees single coherent interface (orchestrator) not multiple agent interfaces\n\n**Human Interaction Points**\n\n- Define workflow phases and validation gates\n- Approve phase transitions through orchestrator interface\n- Receive synthesized results and decision points from orchestrator\n\n**Common Pitfalls**\n\n- **Orchestrator Overreach:** Orchestrator \"helping\" by doing execution work\n- **Bypass:** Specialized agents communicating directly with human, bypassing orchestrator\n- **State Fragmentation:** Workflow state scattered across multiple agents instead of centralized\n\n**Configurable Defaults**\n\n- Orchestrator execution permissions: None (coordination and delegation only)\n- Human interface point: Orchestrator only (specialized agents do not interface directly)\n\n---\n",
      "line_range": [
        249,
        304
      ],
      "metadata": {
        "keywords": [
          "design",
          "architecture",
          "structure",
          "pattern",
          "separation",
          "orchestrator"
        ],
        "synonyms": [
          "design",
          "structure",
          "layout",
          "framework"
        ],
        "trigger_phrases": [
          "agent architecture",
          "system design"
        ],
        "failure_indicators": [
          "poor design",
          "bad architecture",
          "structural issue"
        ],
        "aliases": [
          "A3"
        ]
      }
    },
    {
      "id": "multi-A4",
      "domain": "multi-agent",
      "series_code": "A",
      "number": 4,
      "title": "Intent Propagation",
      "content": "### A4. Intent Propagation\n\n**Why This Principle Matters**\n\nIn multi-agent systems, the original user goal can degrade through agent chains\u2014the \"telephone game\" effect where each handoff loses fidelity to the original intent. The constitutional principle MA3 (Intent Preservation) requires that the \"Why\" be passed as an immutable context object to every agent. Without explicit intent propagation, downstream agents optimize for their local task at the expense of the global goal.\n\n**Domain Application (Binding Rule)**\n\nThe original user intent must propagate through the entire agent chain as an immutable context object. Every agent, regardless of depth in the delegation hierarchy, must have visibility to the root goal and constraints. Agents must verify their outputs serve the original intent, not just their immediate task instructions.\n\n**Constitutional Basis**\n\n- MA3 (Intent Preservation): The \"Why\" must be passed to every agent in the chain\n- C2 (Single Source of Truth): Original intent is authoritative throughout workflow\n- O5 (Explicit Over Implicit): Intent must be explicit, not assumed from context\n\n**Truth Sources**\n\n- Original user request/goal statement\n- Constraint documentation from initial specification\n- Product Owner clarifications on intent\n\n**How AI Applies This Principle**\n\n1. Capture original intent at workflow initiation (goal + constraints + success criteria)\n2. Include intent context object in every handoff, regardless of delegation depth\n3. Before completing any task, verify: \"Does this output serve the original user goal?\"\n4. Flag intent drift to orchestrator when local optimization conflicts with global goal\n5. Never modify the intent context object\u2014it is immutable throughout the workflow\n\n**Success Criteria**\n\n- Every agent in chain can articulate the original user goal\n- Intent context object present in all handoffs\n- No agent optimizes local metrics at expense of global goal\n- Intent drift detected and flagged before output delivery\n\n**Human Interaction Points**\n\n- Clarify intent when ambiguous or conflicting (e.g., \"fast but high quality\")\n- Update intent context if goals change mid-workflow\n- Resolve conflicts between local task requirements and global intent\n\n**Common Pitfalls**\n\n- **Task Tunnel:** Agent optimizes its specific metric (shortest code) at expense of global goal (readability)\n- **Intent Erosion:** Each handoff summarizes away critical constraints\n- **Assumed Context:** Downstream agents \"guess\" at intent instead of receiving explicit object\n\n**Configurable Defaults**\n\n- Intent context format: Structured object with Goal + Constraints + Success Criteria (format configurable)\n- Intent verification: Required before task completion\n\n---\n\n## Coordination Principles (R-Series)\n",
      "line_range": [
        305,
        362
      ],
      "metadata": {
        "keywords": [
          "intent",
          "design",
          "architecture",
          "structure",
          "pattern",
          "propagation"
        ],
        "synonyms": [
          "design",
          "structure",
          "layout",
          "framework"
        ],
        "trigger_phrases": [
          "agent architecture",
          "system design"
        ],
        "failure_indicators": [
          "poor design",
          "bad architecture",
          "structural issue"
        ],
        "aliases": [
          "A4"
        ]
      }
    },
    {
      "id": "multi-R1",
      "domain": "multi-agent",
      "series_code": "R",
      "number": 1,
      "title": "Explicit Handoff Protocol",
      "content": "### R1. Explicit Handoff Protocol\n\n**Why This Principle Matters**\n\nThe constitutional principle MA2 (Handoffs) requires that transitions maintain state and avoid rework. In multi-agent systems with isolated contexts, handoffs are the ONLY mechanism for transferring work between agents. Implicit or informal handoffs lose critical information and force downstream agents to guess or hallucinate context. Additionally, MA5 (Standardized Protocols) requires structured contracts rather than conversational exchange\u2014natural language is ambiguous; structured data is precise.\n\n**Domain Application (Binding Rule)**\n\nEvery inter-agent transfer must follow an explicit handoff protocol that includes: task definition, relevant context, acceptance criteria, and constraints. Handoffs must use structured data formats, not conversational natural language. All handoffs must include deadlock prevention mechanisms (timeouts, retry limits). The receiving agent must have sufficient information to complete its task without accessing the sending agent's context.\n\n**Constitutional Basis**\n\n- MA2 (Handoffs): Transitions maintain state and avoid rework\n- MA5 (Standardized Protocols): Structured contracts, not natural language; deadlock prevention required\n- C1 (Context Engineering): Load necessary information to prevent hallucination\n- G3 (Documentation): Capture decisions for future reference\n\n**Truth Sources**\n\n- Azilen Enterprise Patterns: Log every handoff between agents for traceability\n- LangChain: Handoff patterns with explicit state transfer\n- MA5: \"All interactions must have defined timeouts to prevent deadlocks\"\n\n**How AI Applies This Principle**\n\n1. Define handoff schema for each agent-to-agent transfer type\n2. Use structured data format (not conversational prose) for all handoffs\n3. Include: task definition, input context, acceptance criteria, constraints, relevant prior decisions\n4. Specify timeout and retry limits for every handoff to prevent deadlocks\n5. Validate handoff completeness and schema compliance before executing transfer\n6. Log all handoffs for traceability and debugging\n7. Receiving agent confirms understanding before proceeding\n\n**Success Criteria**\n\n- Every handoff follows defined structured schema\n- No conversational/prose handoffs between agents\n- Timeout and retry limits specified for all transfers\n- Receiving agent can complete task without querying sending agent\n- Handoff log enables reconstruction of decision flow\n- No deadlocks (agents waiting indefinitely for each other)\n\n**Human Interaction Points**\n\n- Define handoff schema for novel agent interactions\n- Review handoff logs when debugging multi-agent issues\n- Resolve schema validation failures that agents cannot auto-resolve\n- Approve handoff content for high-stakes transitions\n\n**Common Pitfalls**\n\n- **Context Assumptions:** Assuming receiving agent \"knows\" what sending agent knows\n- **Chatty Handoffs:** Agents sending paragraphs of prose instead of structured data\n- **Implicit References:** \"Continue with the approach\" without specifying which approach\n- **Missing Constraints:** Handoff includes task but not boundaries or acceptance criteria\n- **Infinite Wait:** Agent A waiting for Agent B, who is waiting for Agent A (deadlock)\n\n**Configurable Defaults**\n\n- Handoff schema: Task + Context + Criteria + Constraints (required fields)\n- Handoff format: Structured data (specific format in methods)\n- Timeout specification: Required (values configurable per task type)\n- Handoff logging: Required (format configurable per tool)\n\n---\n",
      "line_range": [
        363,
        428
      ],
      "metadata": {
        "keywords": [
          "explicit",
          "handoff",
          "protocol"
        ],
        "synonyms": [],
        "trigger_phrases": [],
        "failure_indicators": [],
        "aliases": [
          "R1"
        ]
      }
    },
    {
      "id": "multi-R2",
      "domain": "multi-agent",
      "series_code": "R",
      "number": 2,
      "title": "Orchestration Pattern Selection",
      "content": "### R2. Orchestration Pattern Selection\n\n**Why This Principle Matters**\n\nDifferent task types require different coordination patterns. Sequential patterns ensure dependencies are respected; parallel patterns maximize throughput; hierarchical patterns manage complexity. Applying the wrong orchestration pattern creates either unnecessary bottlenecks (over-serialization) or coordination failures (inappropriate parallelization). Pattern selection should match task characteristics, not developer preference. Additionally, the original multi-agent architecture research demonstrates that enforcing sequential dependencies prevents specification gaps that force AI to make architectural decisions during implementation.\n\n**Domain Application (Binding Rule)**\n\nSelect orchestration pattern based on task characteristics: use sequential for dependent tasks, parallel for independent tasks, hierarchical for complex multi-level delegation. The orchestrator enforces the selected pattern and prevents pattern violations. For sequential dependencies: Phase N+1 cannot begin until Phase N validation passes. Upstream changes must trigger downstream re-validation.\n\n**Constitutional Basis**\n\n- MA5 (Coordination Protocols): Established protocols govern interaction\n- O1 (Iterative Design): Appropriate workflow for task complexity\n- C7 (Inversion of Control): Reason backward from goal to identify dependencies\n- Q3 (Fail-Fast): Catch dependency violations early\n\n**Truth Sources**\n\n- Microsoft Azure: Sequential, concurrent, and group chat orchestration patterns\n- Databricks: Continuum from chains to single-agent to multi-agent\n- Confluent: Orchestrator-worker, hierarchical, blackboard, market-based patterns\n- Original architecture: \"Phase progression must be unidirectional with validation gates\"\n\n**How AI Applies This Principle**\n\n1. Analyze task for dependencies between subtasks\n2. Identify parallelization opportunities (independent subtasks)\n3. Select pattern: Sequential (dependent), Parallel (independent), Hierarchical (complex delegation)\n4. Configure orchestrator to enforce selected pattern\n5. For sequential patterns: Block Phase N+1 until Phase N validation passes\n6. When upstream changes occur, trigger downstream re-validation\n7. Monitor for pattern violations and adjust as needed\n\n**Success Criteria**\n\n- Pattern selection documented with rationale\n- Dependent tasks execute sequentially with validation gates\n- Independent tasks execute in parallel where beneficial\n- Complex tasks use hierarchical delegation appropriately\n- No dependency violations (downstream before upstream)\n- Upstream changes trigger appropriate downstream re-validation\n- Orchestrator actively prevents out-of-order execution\n\n**Human Interaction Points**\n\n- Approve pattern selection for novel or ambiguous task structures\n- Override automatic pattern selection when domain knowledge indicates different approach\n- Define dependencies that may not be obvious from task description\n- Approve phase transitions in sequential workflows\n\n**Common Pitfalls**\n\n- **Over-Serialization:** Sequential pattern for independent tasks (wastes time)\n- **Unsafe Parallelization:** Parallel pattern for dependent tasks (produces errors)\n- **Flat Hierarchy:** Single-level delegation for complex multi-level tasks\n- **Gate Bypass:** Skipping validation to \"save time\" (causes rework cascades)\n- **Ignored Re-validation:** Upstream changes not propagating to downstream phases\n\n**Configurable Defaults**\n\n- Default pattern: Sequential (safest; opt into parallel when dependencies confirmed)\n- Dependency analysis: Required before parallel execution\n- Validation gates: Required between sequential phases\n\n---\n",
      "line_range": [
        429,
        495
      ],
      "metadata": {
        "keywords": [
          "orchestration",
          "selection",
          "pattern"
        ],
        "synonyms": [],
        "trigger_phrases": [],
        "failure_indicators": [],
        "aliases": [
          "R2"
        ]
      }
    },
    {
      "id": "multi-R3",
      "domain": "multi-agent",
      "series_code": "R",
      "number": 3,
      "title": "State Persistence Protocol",
      "content": "### R3. State Persistence Protocol\n\n**Why This Principle Matters**\n\nMulti-agent systems amplify the stateless session problem. Individual agent context, orchestration state, delegation history, and cross-agent decisions all require persistence to maintain coherence across sessions. The constitutional principle G3 (Documentation) requires capturing decisions for future reference; for multi-agent systems, this means comprehensive state management that enables any future session to reconstruct context and continue work.\n\n**Domain Application (Binding Rule)**\n\nMulti-agent workflow state must be persisted to structured files that survive session boundaries. State includes: current phase, agent assignments, completed tasks, pending handoffs, key decisions, and validation results. Session start must load persisted state; session end must save current state.\n\n**Constitutional Basis**\n\n- G3 (Documentation): Capture decisions for future reference\n- MA2 (Handoffs): Transitions maintain state\u2014includes cross-session transitions\n- C1 (Context Engineering): Load necessary information\u2014includes prior session context\n\n**Truth Sources**\n\n- AWS Bedrock AgentCore Memory: Short-term and long-term memory separation\n- AI Coding Methods: SESSION-STATE.md, PROJECT-MEMORY.md patterns\n- Context engineering research: Working memory + long-term memory architecture\n\n**How AI Applies This Principle**\n\n1. Define state schema covering all critical workflow information\n2. Save state at session end and after significant milestones\n3. Load state at session start before any agent work\n4. Include: phase, assignments, decisions, validations, pending work, context summaries\n5. Validate state integrity on load; flag corruptions for human review\n\n**Success Criteria**\n\n- New session can reconstruct full workflow context from persisted state\n- No \"what were we working on?\" confusion across sessions\n- State files are human-readable for debugging and auditing\n- State corruption is detected and flagged, not silently accepted\n\n**Human Interaction Points**\n\n- Review state files when resuming complex multi-session projects\n- Resolve state conflicts or corruptions\n- Define state retention policy for long-running projects\n\n**Common Pitfalls**\n\n- **State Amnesia:** Starting fresh each session, losing prior progress\n- **State Bloat:** Persisting everything, creating unmanageable state files\n- **Implicit State:** Relying on conversation history instead of explicit state files\n\n**Configurable Defaults**\n\n- State file format: Markdown (human-readable, tool-agnostic)\n- State save triggers: Session end + phase completion + significant decisions\n- State retention: Until project completion (archive policy configurable)\n\n---\n",
      "line_range": [
        496,
        552
      ],
      "metadata": {
        "keywords": [
          "persistence",
          "state",
          "protocol"
        ],
        "synonyms": [],
        "trigger_phrases": [],
        "failure_indicators": [],
        "aliases": [
          "R3"
        ]
      }
    },
    {
      "id": "multi-R4",
      "domain": "multi-agent",
      "series_code": "R",
      "number": 4,
      "title": "Observability Protocol",
      "content": "### R4. Observability Protocol\n\n**Why This Principle Matters**\n\nThe constitutional principle MA6 (Synchronization & Observability) requires that long-running agents proactively broadcast their status rather than operating as \"black boxes\" until completion. Without observability, the orchestrator cannot detect stalls, resource contention, or silent failures until they cascade into system-wide problems. Proactive status visibility enables rapid unblocking and dynamic re-planning.\n\n**Domain Application (Binding Rule)**\n\nLong-running agents must proactively broadcast status (current task, progress, blockers) to the orchestrator at defined intervals. Agents must not operate silently until completion. The orchestrator must have visibility into all active agent states to detect stalls, deadlocks, and resource contention before they become failures.\n\n**Constitutional Basis**\n\n- MA6 (Synchronization & Observability): Agents must implement heartbeat/standup mechanism\n- MA4 (Blameless Error Reporting): Proactive reporting of blockers and issues\n- Q3 (Fail-Fast): Detect problems early through visibility\n\n**Truth Sources**\n\n- MA6: \"Long-running agents must proactively broadcast status at defined intervals\"\n- Enterprise patterns: Real-time situational awareness for orchestrators\n- Azilen: Log every step in the process, create metrics for monitoring\n\n**How AI Applies This Principle**\n\n1. Define status broadcast requirements for each agent type\n2. Long-running agents emit periodic status: current task, progress, blockers, estimate\n3. Agents proactively signal blockers (\"I am waiting on Agent B\") rather than silently timing out\n4. Orchestrator monitors all active agent states for anomalies\n5. Detect stalls, deadlocks, and resource contention through status analysis\n6. Status updates are structured and concise (not conversational) to minimize overhead\n\n**Success Criteria**\n\n- No agent operates as \"black box\" for extended periods\n- Orchestrator can query state of all active agents at any time\n- Blockers surfaced proactively, not discovered after timeout\n- Stalls and deadlocks detected before they cascade\n- Status overhead does not exceed value (concise, structured updates)\n\n**Human Interaction Points**\n\n- Define status broadcast frequency for different agent/task types\n- Review status dashboards for complex multi-agent workflows\n- Intervene when orchestrator detects unresolvable blockers\n- Adjust observability levels based on workflow criticality\n\n**Common Pitfalls**\n\n- **Black Box:** Agent goes silent for extended period, orchestrator cannot tell if stuck or working\n- **Micromanager:** Status updates so frequent that agents spend more tokens reporting than working\n- **Silent Blocker:** Agent waiting on external resource without signaling, causing invisible delays\n- **Chatty Status:** Conversational status updates that waste tokens and obscure signal\n\n**Configurable Defaults**\n\n- Status broadcast: Required for tasks exceeding defined duration threshold\n- Status format: Structured data (not conversational)\n- Blocker escalation: Immediate upon detection\n\n---\n\n## Quality Principles (Q-Series)\n",
      "line_range": [
        553,
        615
      ],
      "metadata": {
        "keywords": [
          "observability",
          "protocol"
        ],
        "synonyms": [],
        "trigger_phrases": [],
        "failure_indicators": [],
        "aliases": [
          "R4"
        ]
      }
    },
    {
      "id": "multi-Q1",
      "domain": "multi-agent",
      "series_code": "Q",
      "number": 1,
      "title": "Validation Independence",
      "content": "### Q1. Validation Independence\n\n**Why This Principle Matters**\n\nAgents cannot objectively validate their own work\u2014confirmation bias causes self-assessment to skew positive regardless of actual quality. The constitutional principle Q1 (Verification) requires validation against requirements; for multi-agent systems, this means dedicating separate agents to validation with fresh context and explicit criteria. The Generator-Critic pattern separates creation from validation, ensuring independent quality assessment. Additionally, MA4 (Blameless Error Reporting) requires that outputs include confidence indication so reviewers can calibrate their scrutiny.\n\n**Domain Application (Binding Rule)**\n\nValidation must be performed by a dedicated agent separate from the agent that produced the output. The validation agent operates with fresh context, explicit acceptance criteria, and no access to the generator's reasoning or justifications. Validation results are pass/fail with specific findings, not subjective assessments. All significant outputs must include confidence indication from the producing agent to guide validation intensity.\n\n**Constitutional Basis**\n\n- Q1 (Verification): Validate outputs against requirements\n- MA1 (Role Segregation): Validation is a distinct cognitive function from generation\n- MA4 (Blameless Error Reporting): Confidence scoring on critical outputs; accuracy over completion\n- Q3 (Fail-Fast): Flag low-confidence outputs for enhanced review\n\n**Truth Sources**\n\n- Google ADK: Generator-Critic pattern separates creation from validation\n- Enterprise patterns: Independent validation agents for quality assurance\n- MA4: \"Every critical output must be accompanied by a confidence score\"\n- Research: Confirmation bias documented in self-assessment scenarios\n\n**How AI Applies This Principle**\n\n1. Define validation agent with critic/reviewer cognitive function\n2. Spawn validation agent with fresh context (not generator's context)\n3. Producing agent includes confidence indication with output\n4. Low-confidence outputs receive enhanced validation scrutiny\n5. Provide explicit acceptance criteria\u2014not \"is this good?\" but specific checkpoints\n6. Receive structured validation results: pass/fail + specific findings\n7. Route failures back to appropriate agent for correction\n\n**Success Criteria**\n\n- Every significant output passes through independent validation\n- Validation agent has no access to generator's internal reasoning\n- All outputs include confidence indication from producing agent\n- Low-confidence outputs flagged for enhanced review\n- Validation criteria are explicit and checkable\n- Validation failures include specific, actionable findings\n\n**Human Interaction Points**\n\n- Define validation criteria for novel output types\n- Review validation findings for high-stakes outputs\n- Review all low-confidence outputs regardless of validation pass\n- Resolve disagreements between generator and validator\n\n**Common Pitfalls**\n\n- **Self-Validation:** Generator agent assessing its own work\n- **Context Pollution:** Validator loaded with generator's reasoning and justifications\n- **Missing Confidence:** Outputs delivered without confidence indication\n- **Vague Criteria:** \"Validate this is good\" instead of specific acceptance criteria\n- **Rubber Stamping:** Validator always passing due to insufficient criteria\n- **Ignored Low-Confidence:** Proceeding with uncertain outputs without enhanced review\n\n**Configurable Defaults**\n\n- Validation coverage: All phase-completing outputs (minimum)\n- Validation agent context: Fresh spawn, criteria + output only (no generator context)\n- Confidence indication: Required on all significant outputs\n- Low-confidence threshold: Triggers enhanced validation (threshold configurable)\n\n---\n",
      "line_range": [
        616,
        683
      ],
      "metadata": {
        "keywords": [
          "independence",
          "validation",
          "verification",
          "evidence",
          "testing",
          "quality"
        ],
        "synonyms": [
          "verify",
          "validate",
          "test",
          "check",
          "confirm"
        ],
        "trigger_phrases": [
          "ensure quality",
          "run tests",
          "validate output"
        ],
        "failure_indicators": [
          "unverified",
          "no evidence",
          "untested",
          "broke"
        ],
        "aliases": [
          "Q1"
        ]
      }
    },
    {
      "id": "multi-Q2",
      "domain": "multi-agent",
      "series_code": "Q",
      "number": 2,
      "title": "Fault Tolerance and Graceful Degradation",
      "content": "### Q2. Fault Tolerance and Graceful Degradation\n\n**Why This Principle Matters**\n\nMulti-agent systems have multiple failure points\u2014any agent can fail, any handoff can corrupt, any context can overflow. Without explicit fault tolerance, a single failure cascades through the agent network, corrupting all downstream outputs. The constitutional principle Q3 (Fail-Fast) requires catching failures early; for multi-agent systems, this extends to isolating failures and degrading gracefully. Additionally, MA4 (Blameless Error Reporting) establishes that any agent can \"stop the line\" when critical issues are detected\u2014this authority must be preserved and respected.\n\n**Domain Application (Binding Rule)**\n\nMulti-agent workflows must implement fault isolation and graceful degradation. Agent failures must not cascade to other agents. Failed operations must be retried, escalated, or gracefully degraded\u2014never silently ignored or passed downstream. Any agent detecting a critical safety or logic flaw can halt the entire workflow (\"stop the line\") without penalty. The orchestrator detects failures and implements recovery or degradation protocols.\n\n**Constitutional Basis**\n\n- Q3 (Fail-Fast): Catch failures early and prevent propagation\n- Q7 (Failure Recovery): Explicit strategies for recovering from errors\n- MA4 (Blameless Error Reporting): Any agent can halt workflow; reporting failure is success\n- G3 (Documentation): Log all failures, near-misses, and recovery actions\n\n**Truth Sources**\n\n- Microsoft Azure: Checkpoint features for recovery from interrupted orchestration\n- Databricks: Retry strategies, fallback logic, simpler fallback chains\n- Azilen: Fallback paths for resilience; if one agent fails, system remains functional\n- MA4: \"The 'Stop the Line' Cord: Any agent can halt the entire assembly line\"\n\n**How AI Applies This Principle**\n\n1. Define failure detection for each agent type (timeout, error response, validation failure)\n2. Implement retry strategy: how many attempts, with what modifications\n3. Define fallback: alternative agent, simplified approach, or graceful degradation\n4. Isolate failures: failed agent's outputs do not propagate to other agents\n5. Honor stop-the-line: any agent detecting critical flaw can halt workflow\n6. Log all failures and near-misses for system improvement\n7. Escalate unrecoverable failures to human with full context\n\n**Success Criteria**\n\n- Agent failures detected within defined timeout\n- Retry attempts logged with modifications\n- Fallback strategies defined for all critical agents\n- Stop-the-line authority respected regardless of source agent\n- Unrecoverable failures escalate with actionable context\n- No silent failures or error propagation\n- Near-misses logged for system learning\n\n**Human Interaction Points**\n\n- Define acceptable degradation modes for critical workflows\n- Handle escalated unrecoverable failures\n- Respond immediately to stop-the-line events\n- Approve retry/fallback strategies for high-stakes tasks\n- Review near-miss logs for systemic issues\n\n**Common Pitfalls**\n\n- **Silent Failure:** Agent errors ignored, corrupted output passed downstream\n- **Infinite Retry:** Retry loops without modification or escalation\n- **Cascade Acceptance:** Accepting outputs from agents downstream of a failed agent\n- **Missing Timeouts:** Agents hanging indefinitely without failure detection\n- **Penalized Reporting:** Agents pressured to \"always return a result\" instead of reporting failure\n- **Ignored Stop-the-Line:** Workflow continuing despite critical flaw detection\n\n**Configurable Defaults**\n\n- Agent timeout: Configurable per agent type (default: defined in methods)\n- Retry attempts: Defined limit with modification before escalation\n- Failure isolation: Required (failed agent outputs quarantined)\n- Stop-the-line authority: All agents (not configurable\u2014this is the principle)\n- Near-miss logging: Required\n\n---\n",
      "line_range": [
        684,
        754
      ],
      "metadata": {
        "keywords": [
          "tolerance",
          "degradation",
          "fault",
          "validation",
          "verification",
          "evidence",
          "testing",
          "graceful",
          "quality"
        ],
        "synonyms": [
          "verify",
          "validate",
          "test",
          "check",
          "confirm"
        ],
        "trigger_phrases": [
          "ensure quality",
          "run tests",
          "validate output"
        ],
        "failure_indicators": [
          "unverified",
          "no evidence",
          "untested",
          "broke"
        ],
        "aliases": [
          "Q2"
        ]
      }
    },
    {
      "id": "multi-Q3",
      "domain": "multi-agent",
      "series_code": "Q",
      "number": 3,
      "title": "Human-in-the-Loop Protocol",
      "content": "### Q3. Human-in-the-Loop Protocol\n\n**Why This Principle Matters**\n\nMulti-agent systems can generate significant outputs quickly\u2014faster than human review capacity. Without explicit human checkpoints, multi-agent systems can propagate errors at scale or make consequential decisions without appropriate oversight. The constitutional principle G10 (Boundaries of AI Autonomy) establishes that AI should not make organizational decisions autonomously; for multi-agent systems, this means defining clear escalation triggers and approval gates.\n\n**Domain Application (Binding Rule)**\n\nMulti-agent workflows must define explicit human approval points for: phase transitions, high-stakes outputs, irreversible actions, and decisions outside defined boundaries. The orchestrator pauses workflow and presents decision points to the human Product Owner with context, options, and recommendations. Human approval is required before proceeding past defined gates.\n\n**Constitutional Basis**\n\n- G10 (Boundaries of AI Autonomy): AI should not make organizational decisions autonomously\n- MA4 (Stop the Line): Critical issues halt progression\n- P4 (Human-AI Collaboration Boundaries): Appropriate review of AI recommendations\n\n**Truth Sources**\n\n- Google ADK: Human-in-Loop for high-stakes decisions (irreversible, consequential)\n- Enterprise patterns: Approval gates for critical actions\n- Constitutional MA4: Stop-the-line authority for any agent\n\n**How AI Applies This Principle**\n\n1. Identify approval gates: phase transitions, irreversible actions, high-stakes outputs\n2. Define decision point format: context, options, tradeoffs, recommendation, explicit question\n3. Orchestrator pauses workflow at approval gates\n4. Present decision point to human through orchestrator interface\n5. Resume only on explicit human approval\n\n**Success Criteria**\n\n- All defined approval gates trigger human review\n- Decision points include sufficient context for informed decision\n- No bypass of approval gates regardless of urgency claims\n- Human decisions logged with rationale\n\n**Human Interaction Points**\n\n- Define approval gates for specific workflow types\n- Review and approve at defined checkpoints\n- Override or modify AI recommendations as appropriate\n\n**Common Pitfalls**\n\n- **Approval Fatigue:** Too many gates causing rubber-stamp approvals\n- **Gate Bypass:** \"Urgent\" exceptions that skip human review\n- **Insufficient Context:** Decision points that don't provide enough information\n- **Missing Recommendations:** Presenting options without AI recommendation\n\n**Configurable Defaults**\n\n- Minimum approval gates: Phase transitions + irreversible actions\n- Decision point format: 5-part (Context, Options, Tradeoffs, Recommendation, Question)\n- Approval timeout: None (human timing, not system-imposed)\n\n---\n\n## Meta \u2194 Domain Crosswalk\n\n| Constitutional Principle | Multi-Agent Domain Application |\n|--------------------------|-------------------------------|\n| MA1 Role Specialization | A1 Cognitive Function Specialization |\n| MA2 Handoffs | R1 Explicit Handoff Protocol, R3 State Persistence |\n| MA3 Intent Preservation | A4 Intent Propagation |\n| MA4 Blameless Error Reporting | Q1 Validation Independence (confidence), Q2 Fault Tolerance (stop-the-line) |\n| MA5 Coordination Protocols | A3 Orchestrator Separation, R1 Structured Handoffs, R2 Orchestration Patterns |\n| MA6 Synchronization & Observability | R4 Observability Protocol |\n| C1 Context Engineering | A2 Context Isolation Architecture |\n| Q1 Verification | Q1 Validation Independence |\n| Q3 Fail-Fast | Q2 Fault Tolerance and Graceful Degradation |\n| Q7 Failure Recovery | Q2 Fault Tolerance and Graceful Degradation |\n| G3 Documentation | R3 State Persistence Protocol |\n| G10 Boundaries of AI Autonomy | Q3 Human-in-the-Loop Protocol |\n\n---\n\n## Peer Domain Interaction: Multi-Agent + AI Coding\n\nWhen multi-agent systems perform coding tasks, both domain principles apply:\n\n**Multi-Agent Domain Governs:**\n- Agent architecture and specialization (A1, A2, A3)\n- Coordination and handoffs between agents (R1, R2, R3)\n- Validation agent structure and independence (Q1)\n- Fault handling across agent network (Q2)\n- Human approval gates for multi-agent workflow (Q3)\n\n**AI Coding Domain Governs:**\n- Specification completeness before implementation (C1)\n- Code quality and security standards (Q1, Q3)\n- Testing requirements for generated code (Q2)\n- Sequential phase dependencies within coding workflow (P2)\n- Production-ready thresholds for outputs (P3)\n\n**Conflict Resolution:**\nIf principles conflict, apply Constitutional Supremacy Clause: S-Series > Meta-Principles > Domain Principles. If domain principles conflict at same level, the more restrictive interpretation applies (safety-first).\n\n---\n\n## Glossary\n\n**Agent:** An AI instance with defined cognitive function, context window, and task scope operating as part of a multi-agent system.\n\n**Cognitive Function:** A mental model or reasoning pattern (strategic analysis, creative synthesis, critical evaluation, etc.) that defines an agent's specialized capability.\n\n**Context Isolation:** Architecture ensuring each agent operates in independent context windows without unintended information sharing.\n\n**Context Pollution:** When information from one domain inappropriately influences decisions in an unrelated domain, causing inconsistencies.\n\n**Generator-Critic Pattern:** Separation of content creation (generator agent) from validation (critic agent) to ensure independent quality assessment.\n\n**Graceful Degradation:** System behavior when components fail\u2014maintaining partial functionality rather than complete failure.\n\n**Handoff:** Explicit transfer of task, context, and criteria from one agent to another through structured protocol.\n\n**Orchestrator:** Dedicated agent managing workflow coordination, validation gates, and human interface without executing domain-specific work.\n\n**Orchestration Pattern:** The coordination structure for multi-agent work (sequential, parallel, hierarchical).\n\n**State Persistence:** Mechanisms ensuring workflow context, decisions, and progress survive session boundaries.\n\n**Validation Independence:** Requirement that validation be performed by agents separate from those producing the output.\n\n---\n\n## Appendix A: Version History\n\n| Version | Date | Changes |\n|---------|------|---------|\n| v1.0.0 | 2025-12-21 | Initial release. 11 principles in 3 series (A1-A4, R1-R4, Q1-Q3). Derived from Constitution MA-Series (MA1-MA6 fully mapped), industry research 2024-2025, and practical multi-agent implementation patterns. Full coverage of all Constitutional multi-agent principles. |\n\n---\n\n## Appendix B: Evidence Base Summary\n\nThis framework derives from analysis of 2024-2025 research sources:\n\n**Multi-Agent Performance Research:**\n- Anthropic: Multi-agent systems (Opus lead + Sonnet sub-agents) outperformed single Opus by 90.2%\n- Token usage explains 80% of performance variance in multi-agent systems\n- Specialized agents achieve 300% better performance on domain-specific tasks\n- Cognitive load reduction of 70% with proper specialization\n\n**Context Management Research:**\n- LangChain: Subagent isolation saves 67% tokens vs. context accumulation\n- Factory.ai: Context as \"scarce, high-value resource\"\n- Context rot: Accuracy decreases as context window fills\n- Four strategies: Writing, Selecting, Compressing, Isolating context\n\n**Orchestration Pattern Research:**\n- Microsoft Azure: Sequential, concurrent, group chat orchestration patterns\n- Google ADK: Generator-Critic, Human-in-Loop, Hierarchical patterns\n- Databricks: Continuum from chains to single-agent to multi-agent\n- LangChain: Handoffs, Skills, Router, Subagents pattern comparison\n\n**Fault Tolerance Research:**\n- Microsoft Azure: Checkpoint features for recovery\n- Enterprise patterns: Fallback paths, resilience design\n- Retry strategies with modification before escalation\n\n---\n\n## Appendix C: Extending This Framework\n\n### How to Add a New Multi-Agent Principle\n\n1. **Identify Failure Mode:** Document the specific multi-agent failure mode that current principles do not address\n2. **Research Validation:** Gather evidence (2024-2025 sources preferred) supporting the failure mode's significance\n3. **Constitutional Mapping:** Identify which Meta-Principle(s) the new principle derives from\n4. **Gap Analysis:** Explain why Meta-Principles alone are insufficient for this failure mode\n5. **Series Classification:** Use this decision tree:\n   - Does it address agent STRUCTURE or BOUNDARIES? \u2192 **A-Series**\n   - Does it govern COMMUNICATION or WORKFLOW? \u2192 **R-Series**\n   - Does it ensure OUTPUT QUALITY or SAFETY? \u2192 **Q-Series**\n6. **Template Completion:** Write all fields of the principle template\n7. **Crosswalk Update:** Add entry to Meta \u2194 Domain Crosswalk table\n8. **Validation:** Ensure no overlap with existing principles\n\n### Distinguishing Principles from Methods\n\n| Question | Principle | Method |\n|----------|-----------|--------|\n| Is it a universal requirement regardless of tooling? | \u2713 | |\n| Can it be satisfied by multiple different implementations? | \u2713 | |\n| Does it address a fundamental multi-agent constraint? | \u2713 | |\n| Is it a specific tool, command, or configuration? | | \u2713 |\n| Could it be substituted with equivalent alternatives? | | \u2713 |\n| Does it specify exact numeric thresholds? | | \u2713 (use configurable defaults) |\n\n---\n\n**End of Document**\n\n[Methods document (multi-agent-methods.md) will provide operational procedures implementing these principles]\n",
      "line_range": [
        755,
        950
      ],
      "metadata": {
        "keywords": [
          "human-in-the-loop",
          "validation",
          "verification",
          "protocol",
          "evidence",
          "testing",
          "quality"
        ],
        "synonyms": [
          "verify",
          "validate",
          "test",
          "check",
          "confirm"
        ],
        "trigger_phrases": [
          "ensure quality",
          "run tests",
          "validate output"
        ],
        "failure_indicators": [
          "unverified",
          "no evidence",
          "untested",
          "broke"
        ],
        "aliases": [
          "Q3"
        ]
      }
    }
  ],
  "methods": [],
  "last_extracted": "2025-12-24T21:37:58.422689+00:00"
}